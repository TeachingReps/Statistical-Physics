% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
\documentclass[letterpaper,english,10pt]{article}
\input{../../header}



\title{Lecture-13: The Monte Carlo Method}

\begin{document}
\maketitle
\section{The Monte Carlo Method}
In fields like Statistical Physics and Combinatorial Optimization we often come across the problem of sampling a configuration $X \in \sX^N$
from a given distribution $P(X)$. This can be difficult when N is large, because there are too many configurations and or because the distribution $P(X)$ is specified by Boltzmann formula with computationally infeasible Partition Function. This motivates the study of Monte Carlo Method.

\subsection{Properties of Markov Chains}
Let $(X_t \in \sX^N:t \in N)$ be a Markov chain with state space $\sX^N$, and set of transition rates $w(x \to y)$ with $x,y \in \sX^N$, which satisfy the following conditions.

\begin{enumerate}[(i)]
\item \textbf{Irreducibility :} For any pair of configurations $x,y \in \sX^N$, there exists a path $(x_0,x_1,\dots, x_n)$ of length n, connecting $x_0 = x$ and $x_n = y$ with non-zero probability, i.e.
$w(x_i \to x_{i+1}) > 0$ for all $i \in \{0,\dots,n-1\}$.

\item \textbf{Aperiodicity :} For any pair of configurations $x,y \in \sX^N \times \sX^N$, there exists a positive integer $n(x,y)$ such that for any $n \geq n(x,y)$, there exists a path of length $n$ connecting $x$ and $y$ with non-zero probability. Notice that, for an irreducible chain, aperiodicity is easily enforced by allowing the configuration to remain unchanged with non-zero probability: $w(x \to x) > 0$.

\item \textbf{Stationarity :} There exists a distribution $\pi \in \sM(\sX^N)$ such that
\EQ{\sum_{x \in \sX^N}\pi(x)w(x \to y) = \pi(y) \hspace{3em}\forall y \in \sX^N .}
\item \textbf{Reversibility :} The transition probability satisfy the detailed balance equation
\EQ{\pi(x)w(x \to y) = \pi(y)w(y \to x) \hspace{3em}\forall x,y \in \sX^N .}
\end{enumerate}
\textbf{Note :}
 For Finite chains Irreducibility and Aperiodicity implies Stationarity.
\begin{thm}
 Let $X_0,X_1,\dots, X_t,\dots $ be random variables distributed according to the Markov chain with transition probabilites $w(x \to y)$ and initial condition $X_0 = x_0$.Let the Markov chain satisfy the conditions $(\romannumeral 1) - (\romannumeral 3)$ . Let $f: \sX^N \to \R$ be any real valued function. Then
\begin{enumerate}
\item The probability distribution of $X_t$ converges to the stationary distribution:
\EQ{\lim_{t \to \infty} P[X_t = x] = \pi(x).}
\item Time averages converge to averages over the stationary distribution
\EQ{\lim_{t \to \infty} \frac{1}{t} \sum_{s = 1}^{t}f(X_s) = \sum_{x}\pi(x)f(x) \hspace{3em} almost \: surely.}
\end{enumerate}
\end{thm}
%\begin{proof}
%The proof of this Theorem can be found in any textbook on Markov %processes.
%\end{proof}
The \textbf{Goal} is to design and simulate a process that converges to the stationary distribution of interest.

\section{Metropolis Chains}
\textbf{Goal :} Given state space $\sX^N$ and stationary distribution $\pi$, find a Markov chain with transition probability matrix P such that $\pi P = \pi$.
\newline
The approach of Metropolis chains is to first consider an initial base markov chain with certain transition probability matrix and modify the transition probabilities appropriately so that the new chain has the desired stationary distribution. 

\subsection{Symmetric base chain}
Let $\psi$ be a symmetric transition probability matrix of the base chain over $\sX^N$.
\newline
Since $\psi$ is symmetric and has vector of ones as an eigenvector, it is easy to see that $\psi$ satisfies reversibility with respect to uniform distribution on $\sX^N$, i.e.
\EQ{\psi\mathbb{1} = \mathbb{1} \implies \frac{\mathbb{1}^T}{|\sX^N|}\psi = \frac{\mathbb{1}^T}{|\sX^N|} \implies \frac{1}{|\sX^N|}\psi(x,y) = \frac{1}{|\sX^N|}\psi(y,x) \; \forall \: x,y \in \sX^N}

Note that $\psi(x,\cdot)$ is the distribution over next state, starting from state $x$.
Define $a(x,y)$ as the acceptance probability of transition from $x$ to $y$.
The new chain evolves as follows : when at state $x$, a candidate move is generated from distribution $\psi(x,\cdot)$. If the proposed new state is $y$, then the move is "accepted" with probability $a(x,y)$ and with remaining probability chain remains at $x$. Thus the transition probabilities of the new chain becomes,

\EQ{P(x,y) = \begin{cases}\psi(x,y)a(x,y) & if \; y \neq x \\ 1 - \sum\limits_{z:z \neq x} \psi(x,z)a(x,z) & if \; y = x \end{cases}}

The transition matrix P has stationary distribution $\pi$ if reversibility condition holds, i.e.
\EQ{\pi(x)\psi(x,y)a(x,y) = \pi(y)\psi(y,x)a(y,x) \hspace{3em} \forall x \neq y}
Define $b(x,y) = \pi(x)a(x,y)$.Thus the condition becomes 
\EQ{b(x,y) = b(y,x) \hspace{3em} \forall x \neq y}
By definition we see that,
\EQ{b(x,y) \leq \pi(x)}
\EQ{b(y,x) \leq \pi(y)}
Thus,
\EQ{b(x,y) = b(y,x) \leq \min\{\pi(x),\pi(y)\}}
\EQ{a(x,y) \leq \min\{1,\frac{\pi(y)}{\pi(x)}\}}
Choose 
\EQ{a(x,y) = 1 \wedge \left(\frac{\pi(y)}{\pi(x)}\right) := \min\{1,\frac{\pi(y)}{\pi(x)}\}}
This choice of acceptance probability is called Metropolis Hastings.
The \textbf{Metropolis Chain} for probability distribution $\pi$ and symmetric transition probability matrix $\psi$ is defined as

\EQ{P(x,y) = \begin{cases}\psi(x,y)\left[1 \wedge \frac{\pi(y)}{\pi(x)}\right] & if \; y \neq x \\ 1 - \sum\limits_{z:z \neq x} \psi(x,z)\left[1 \wedge \frac{\pi(z)}{\pi(x)}\right] & if \; y = x \end{cases}}
\textbf{Remark :} If the desired stationary distribution $\pi$ is a Boltzmann distribution, this method has an advantage that we don't need to compute partition function explicitly which is computationally infeasible in many cases.
\begin{shaded}
\begin{exmp}[Metropolis algorithm for $N$-particle system]
Consider a system of $N$ Ising spins $\sigma = (\sigma_1 \dots \sigma_N)$ with energy function $E(\sigma)$ and inverse temperation $\beta$. We are interested in sampling the Boltzmann distribution $\mu_\beta = \frac{e^{-\beta E(\sigma)}}{Z_\beta}$. The \textbf{Metropolis algorithm} with random updatings is defined as follows. Call $\sigma^{(i)}$ the configuration which coincides with $\sigma$ but for the site $i$ i.e.   
\EQ{\sigma^{(i)} : \begin{cases} \sigma_j^{(i)} = \sigma_j & i \neq j \\ \sigma_i^{(i)} = -\sigma_i \end{cases}} 
  and let $\Delta E_i(\sigma) \equiv E(\sigma^{(i)}) - E(\sigma)$. At each step, an integer $i \in [N]$ is chosen randomly with flat probability distribution and the spin $\sigma_i$ is flipped with probability
 \EQ{w_i(\sigma) = \exp \{-\beta \max[\Delta E_i(\sigma),0]\} = min \{1,\frac{\mu_\beta(\sigma^{(i)})}{\mu_\beta(\sigma)}\}}
We can write transition probability matrix as
\EQ{w(\sigma \to \tau) = \begin{cases} \frac{1}{N}w_i(\sigma) & \tau = \sigma^{(i)} \;\; \forall i = 1,2,\dots,N \\
1 - \frac{1}{N}\sum\limits_{i=1}^{N}w_i(\sigma) & \tau = \sigma \\
0 & otherwise \end{cases}}
Consider the detailed balance equation with respect to $\mu_\beta$
\EQ{\mu_\beta(\sigma)w_i(\sigma) = min\{\mu_\beta(\sigma),\mu_\beta(\sigma^{(i)})\} = \mu_\beta(\sigma^{(i)}) w_i(\sigma^{(i)})}
Thus the chain is Irreducible and Reversible.
\end{exmp}
\end{shaded}
\subsection{General base chain}
The Metropolis chain can also be defined when the initial transition matrix is not symmetric. For a general (irreducible) transition matrix $\psi$ and an arbitrary probability distribution $\pi$ on $\sX^N$, the Metropolized chain is executed as follows. When at state $x$, generate a state $y$ from $\psi(x,\cdot)$. Move to y with probability
\EQ{\frac{\pi(y)\psi(y,x)}{\pi(x)\psi(x,y)} \wedge 1} and remain at x with  the complementary probability. The transition matrix $P$ for this chain is
	
\EQ{P(x,y) = \begin{cases}\psi(x,y)\left[1 \wedge \frac{\pi(y)\psi(y,x)}{\pi(x)\psi(x,y)}\right] & if \; y \neq x \\ 1 - \sum\limits_{z:z \neq x} \psi(x,z)\left[1 \wedge \frac{\pi(z)\psi(z,x)}{\pi(x)\psi(x,z)}\right] & if \; y = x \end{cases}}
\section{Glauber Dynamics}
Glauber Dynamics is similar to Metropolis chains.
The chain evolves as follows: From state $x$ , we choose $v \in [N]$ uniformly at random and move to new state according to $\pi^{x,v}$ defined as
\EQ{\pi^{x,v}(y) = \pi(y | \Omega(x,v)) = \begin{cases}
\frac{\pi(y)}{\pi(\Omega(x,v))} & if \; y \in \Omega(x,v) \\
0 & if \; y \not\in \Omega(x,v)\end{cases}}
where $\Omega(x,v) = \{y \in \sX^N : y(w) = x(w)\; \forall w \neq v \}$.
\begin{shaded}
\begin{exmp}[Glauber Dynamics for N-particle system]
For this system $\Omega(\sigma,i) = \{\sigma,\sigma^{(i)} \}$.
Thus,
\EQ{w_i(\sigma) = \pi^{\sigma,i}(\sigma^{(i)}) = \frac{\mu_\beta(\sigma^{(i)})}{\mu_\beta(\sigma^{(i)}) + \mu_\beta(\sigma)} = \frac{exp(-\beta E(\sigma^{(i)}))}{exp(-\beta E(\sigma^{(i)})) + exp(-\beta E(\sigma))}}
\EQ{w_i(\sigma) = \frac{1}{1 + exp(\beta \Delta E_i(\sigma))} = \frac{1}{2}\left[1 - \frac{exp(\beta \Delta E_i(\sigma)) - 1}{exp(\beta \Delta E_i(\sigma)) + 1} \right]}
\EQ{w_i(\sigma) = \frac{1}{2}\left[ 1 - \tanh\left(\frac{\beta \Delta E_i(\sigma)}{2}\right)\right]}

We can write transition probability matrix as
\EQ{w(\sigma \to \tau) = \begin{cases} \frac{1}{N}w_i(\sigma) & \tau = \sigma^{(i)} \;\; \forall i = 1,2,\dots,N \\
1 - \frac{1}{N}\sum\limits_{i=1}^{N}w_i(\sigma) & \tau = \sigma \\
0 & otherwise \end{cases}}
Consider the detailed balance equation with respect to $\mu_\beta$
\EQ{\mu_\beta(\sigma)w_i(\sigma) = \frac{\mu_\beta(\sigma)\mu_\beta(\sigma^{(i)})}{\mu_\beta(\sigma^{(i)}) + \mu_\beta(\sigma)} = \mu_\beta(\sigma^{(i)})w_i(\sigma^{(i)})}
Thus the chain is Irreducible and Reversible.
\end{exmp}
\end{shaded}

Given a finite set $\Omega$ of the form $\sX^V$ where $V$ is the vertex set of a graph $G = (V,E)$ and $\sX$ is a finite set, we would like to find a transition probability matrix $P$ for which $\pi$ is a stationary distribution on $\Omega$. The elements of $\sX^V$, called \textbf{configurations}, are mappings from $V$ to $\sX$ which can be visualized as labeling of vertices using elements of $\sX$.
\begin{defn}
Given a configuration space $\sX^V$ for a graph $G = (V,E)$, we can define \textbf{Glauber dynamics} or \textbf{Gibbs sampler} to be a the following reversible Markov chain which has stationary distribution $\pi$, 
and transition probabilities for transitioning from state $x$ to $y$ for all ${x,y} \in \sX^V$, 
\EQ{
P(x,y) = \begin{cases}
\frac{1}{N}\frac{\pi(y)}{\pi(s(x,y))}, &y \in s(x),\\
0, & y \notin s(x).
\end{cases}
}
Here, the set of vertices where any two states $x$ and $y$ differ is defined as $V(x,y) = \set{v \in V: x \neq y}$, the set of possible transitions $s(x) = \set{y \in \sX^V: \abs{V(x,y)} = 1}$ and the set of possible transitions at vertex $V(x,y)$ as  $s(x,y)= \set{z \in \sX^V: z_w = x_w, w \in V, w \notin V(x,y)}$. 
\end{defn}
\begin{lem}
the Glauber dynamics is a reversible Markov chain with the stationary distribution $\pi$.
\end{lem}
\begin{proof}
A Markov chain with a stationary distribution $\pi$ is called reversible if and only if 
\EQ{
\pi(x)P(x,y) = \pi(y)P(y,x).
}
for any $x,y \in \Omega$. Substituting $P(x,y)$, we get:
\EQ{
\pi(x)P(x,y) = \frac{1}{N}\frac{\pi(x)\pi(y)}{\pi(s(x,y))} = \pi(y)\frac{1}{N}\frac{\pi(x)}{\pi(s(x,y))} = \pi(y)\frac{1}{N}\frac{\pi(x)}{\pi(s(y,x))} = \pi(y)P(y,x)
}
where $s(x,y) = s(y,x)$ for all $x,y \in \sX^V$ as $\abs{V(x,y)} = 1$. 
\end{proof}
%\begin{exerc}
%Show that the Glauber dynamics is a reversible Markov chain with the stationary distribution $\pi$. 
%\end{exerc}
\begin{shaded}
\begin{exmp}[Graph coloring]
Given a graph $G = (V,E)$ and a set of colors $\set{1,2,\dots,q}$, a proper $q$-coloring of $G$ is an assignment of colors to the vertices $V$ such that neighbouring vertices do not receive the same color, $i.e$, an element $x$ of $\set{1,2,\dots,q}^V \equiv [q]^V$ such that $x(v) \neq x(w) \forall v,w \in E$. We would like to construct a Markov chain on the set of proper $q$-coloring of $G$.
\newline
Given a configuration $x$ and a vertex $v$, a color $j$ is called \textbf{allowable} if $j \notin \set{x(w) : w \sim v}$.
\newline
Given a proper $q$-coloring $x$, a new coloring can be generated by:
\begin{itemize}
\item Selecting a vertex $v \in V$ randomly.
\item Selecting an allowable color $j$ at random from the set of allowable colors for $v$.
\item Applying the chosen color on $v$.
\end{itemize} 
\begin{lem}
The resulting chain has uniform stationary distribution over all proper $q$-coloring.
\end{lem}
\begin{proof}
The transition probability of moving from one configuration $x$ to another configuration $y$ differing over a single vertex $v$ color can be written as:
\EQ{
P(x,y) = \frac{1}{\abs{V}}\frac{1}{\abs{A_v(x)}}
} 
where $A_v(x)$ is the set of allowable colors at $v$, given $x$.
Notice that $A_v(x)$ and $A_v(y)$ are the same as $x$ and $y$ differ only by the color on vertex $v$.
Therefore, $P(x,y) = P(y,x)$. Substituting in delatiled balance equation:
\EQ{
\pi(x) = \pi(y) 
}
implying the stationary distribution over this chain is a uniform stationary distribution.
\end{proof}

\end{exmp}
\end{shaded}
\begin{shaded}
\begin{exmp}[Hardcore configuration]
A hardcore configuration is a placement of particles over the vertices $V$ of a graph such that each vertex is occupied by at most one particle and no two particles are stored on adjacent vertices, that is, for a hardcore configuration $x$:
\EQ{
x \in \set{b : b \in \set{0,1}^V,b(v)b(w) = 0 \forall v \sim w \in V}
}  
The vertice $v$ with $x(v) = 1$ is called \textbf{occupied} and the vertice $v$ with $x(v) = 0$ is called \textbf{vacant}.
\newline
To construct a Markov chain on hardcore configurations, consider:
\begin{itemize}
\item A vertex $v$ is chosen randomly.
\item If any neighbouring vertex is occupied, $v$ is left vacant. Else, a particle is placed on $v$ with probability $\frac{1}{2}$.
\end{itemize}  
\end{exmp}
\end{shaded}
\end{document}
