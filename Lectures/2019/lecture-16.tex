% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
\documentclass[letterpaper,english,10pt]{article}
\input{../../header}

\title{Lecture-16: Mixing times}


\begin{document}
\maketitle

\section{Mixing times}
\begin{defn}
For an irreducible, aperiodic, positive recurrent homogeneous Markov chain $X$ with transition probability matrix $P$ and invariant distribution $\pi$, 
the \textbf{mixing time} is defined as 
\meq{2}{
&t_{\text{mix}}(\epsilon) \triangleq \min\set{t \ge 0: d(t) = \max_{x \in \sX^N}\norm{P^t(x, \cdot)- \pi(\cdot)}_{\text{TV}} \le \epsilon},&&\text{ and } t_{\text{mix}} \triangleq t_{\text{mix}}(1/4).
}
\end{defn}
We can write the following relation 
\EQ{
d(\ell t_{\text{mix}}(\epsilon)) \le \bar{d}(\ell t_{\text{mix}}(\epsilon)) \le \bar{d}( t_{\text{mix}}(\epsilon))^\ell \le 2^\ell d(t_{\text{mix}}(\epsilon))^\ell \le (2\epsilon)^\ell. 
}
For $\epsilon = 1/4$, since $d$ is a non-increasing function, %and $d(t_{\text{mix}}(\epsilon)) \le \epsilon$, 
we can write 
\meq{2}{
&d(\ell t_{\text{mix}}) \le 2^{-\ell} = \epsilon, && t_{\text{mix}}(\epsilon) \le \left\lceil\ln \frac{1}{\epsilon}\right\rceil t_{\text{mix}}.
}

Often one is interested in computing the mean of some observable $\cO: \sX^N \to \R$, 
rather than sampling a configuration from the equilibrium distribution. 
Denoting the expectation with respect to the equilibrium distribution as $\inner{\cdot}$, 
we observe that the mean observable can be computed by averaging over configurations generated by the equilibrium distribution as:
\EQ{
\inner{\cO(X)} = \sum_{x \in \sX^N}\cO(x)\pi(x) = \lim_{t \to \infty}\frac{1}{t}\sum_{s=1}^t\cO(X_s).
}
Suppose $X_0 \sim \pi$, then how many steps are needed to reach close to $\inner{\cO(X)}$? In practice, we don't know $\pi$ and we can reach $\epsilon$ close to it by $P^t(x,\cdot)$ in $\left\lceil\ln \frac{1}{\epsilon}\right\rceil t_{\text{mix}}$ steps for any initial configuration $x$.  
Defining $\cO_t = \cO(X_t)$, we can estimate the mean of the observable by empirical estimate 
\EQ{
\bar{\cO}_t = \frac{1}{t}\sum_{s=0}^{t-1}\cO_s.
}
Since the joint distribution of $(X_s, X_u)$ is same as $(X_0, X_{u-s})$ for $u \ge s$ for a stationary Markov chain, 
we have $\inner{\cO_s; \cO_u} = \inner{\cO_0; \cO_{u-s}}$, where we have used the notation $\inner{X;Y}$ to denote the covariance between random variables $X$ and $Y$. 
We further define the \textbf{autocorrelation function} for the observable $\cO$ as $C_\cO(t-s) \triangleq \frac{\inner{\cO_t; \cO_s}}{\inner{\cO_0; \cO_0}}$. 
We can check that the mean of this estimate is $\inner{\bar{\cO}_t} = \inner{\cO(X)}$ and the variance is given by 
\EQ{
\Var{\bar\cO_t} = \frac{1}{t^2}\sum_{s,u=0}^{t-1}\inner{\cO_s; \cO_u} 
%= \frac{1}{t^2}\left[\sum_{u=0}^{t-1}\left(\sum_{s =0}^{u-1} + \sum_{s=u}+\sum_{s=u+1}^{t-1} \right)\inner{\cO_s; \cO_u}\right]\\
%&= \frac{1}{t^2}\left[\sum_{u=0}^{t-1}\sum_{s=0}^{u-1} \inner{\cO_0; \cO_{u-s}} +t\inner{\cO_0; \cO_0} + \sum_{u=0}^{t-1}\sum_{s=u+1}^{t-1}\inner{\cO_0; \cO_{s-u}} \right]\\
%&= \frac{1}{t^2}\left[\sum_{s=0}^{t-1}\sum_{u=1}^{t-s-1} \inner{\cO_0; \cO_{u}} +t\inner{\cO_0; \cO_0} + \sum_{u=0}^{t-1}\sum_{s=1}^{t-u-1}\inner{\cO_0; \cO_{s}} \right]\\
%&= \frac{1}{t^2}\left[\sum_{s=1}^{t-1}2(t-s) \inner{\cO_0; \cO_{u}} +t\inner{\cO_0; \cO_0}  \right]\\
%&= \frac{1}{t^2}\sum_{s=0}^{t-1}(t-s)\inner{\cO_0; \cO_s},
= \frac{\inner{\cO_0; \cO_0}}{t}\left[-\sum_{s=1}^{t-1}\frac{s}{t}C_\cO(s) +C_\cO(0) + \sum_{s=1}^{t-1}2C_\cO(s) \right].
}
 %so that $\Var{\bar\cO_t} = \frac{\inner{\cO; \cO}}{t^2}\sum_{s=0}^{t-1}(t-s)C_\cO(t)$. 
For irreducible, aperiodic, and positive recurrent Markov chains, the autocorrelation function $\cO(t)$ for certain observables, decreases exponentially as $t \to \infty$. 
Defining the \textbf{integrated autocorrelation time} $t^{\cO}_{\text{int}} \triangleq C_\cO(0) + \sum_{t=1}^\infty 2C_\cO(t)$, we can write 
\EQ{
\Var{\bar\cO_t} = \frac{t^\cO_{\text{int}}}{t}\Var{\cO_0} + O(t^{-2}). 
}
The integrated autocorrelation time $t^{\cO}_{\text{int}}$ determines how long the Monte Carlo simulation should run to get good estimate for the mean $\inner{\cO}$. 
\begin{shaded*}
\begin{exmp}[Curie-Weiss model]
Recall that in the Curie-Weiss model the configuration space $\sX^N = \set{\pm 1}^N$. Let $\sigma = (\sigma_1, \dots, \sigma_N) \in \sX^N$ be a configuration and $m(\sigma) = \frac{1}{N}\sum_{i=1}^N \sigma_i$ denote the value of global magnetization for this configuration $\sigma$. A quantity of interest is the expected value of this observable $m(\sigma)$ under the Boltzmann distribution. Let $\bar{m}$ denote this expected value i.e., $\bar{m} = \inner{m(\sigma)}$ and define $\bar{m}_t$ as:
\EQ{
\bar{m}_t = \frac{1}{t} \sum_{s=0}^{t - 1} m(\sigma^{(i)}), 
}
where $\sigma^{(i)}$ is the $i^{th}$ sample from a Markov chain whose stationary distribution is $\mu_\beta$ (the Boltzmann distribution for Curie-Weiss model). Such a Markov chain can be constructed by following the Glauber dynamics (or heat bath) algorithm as discussed in a previous lecture. Clearly,
\EQ{
\lim_{t \to \infty} \bar{m}_t = \bar{m}.
}
The integrated autocorrelation time can be used to provide an insight about the number of steps needed to get a \textit{close enough} solution. Simulations done with different values of inverse temperature $\beta$ indicate that as $\beta$ increases, the time needed to come close to the correct value of $\bar{m}$ also increases. For larger values of $\beta$, sampling from $\mu_\beta$ using Glauber dynamics becomes exceedingly difficult for this model. 
\end{exmp}
\end{shaded*}
\section{Simulated annealing}
Suppose we are interested in solving an optimization problem in the configuration space $\sX^N$ with the cost function $E(x)$. 
Let $\min_xE(x) = E_0 = 0$, without loss of generality, 
then we are interested in finding the set $\sX^N_0 = \set{x \in \sX^N: E(x) = E_0 = 0}$. 
This problem can be posed as a statistical-physics problem, where the question is to find a Markov chain such that the equilibrium distribution is given by the Boltzmann distribution for energy function $E(x)$ and inverse temperature $\beta$. 
That is, 
\EQ{
\mu_\beta(x) = \frac{1}{Z(\beta)}e^{-\beta E(x)}, \text{ where } Z(\beta) = \sum_y e^{-\beta E(y)}.
}
In the low temperature limit ($\beta \to \infty$) all the mass of distribution $\mu_\beta$ is concentrated on the lowest energy states $x \in \sX_0^N$ and hence the samples obtained from a Monte Carlo method for sampling from $\mu_\beta$ will correspond to the minimizers of the original optimization problem at stationarity, i.e. samples will be drawn from the following distribution:
\EQ{
\mu_\beta(\sX_0^N) = \frac{\abs{\sX_0^N}}{Z(\beta)}.
}
From the ergodic theory, we know that mean time to visit an optimal configuration is given by $\frac{1}{\mu_\beta(\sX_0^N)}$. One could imagine setting $\beta = \infty$ in the beginning itself to sample from $\mu_\beta(\sX_0^N)$, however, such an approach leads to a Markov chain that is not irreducible. This can be seen by considering that the stationary distribution must satisfy the following condition:
\EQ{
\sum_x \mu_\beta(x) w(x \to y) = \mu_\beta(y) \Rightarrow \sum_x \exp(-\beta[E(x) - E(y)]) w(x \to y) = 1.
}
As all terms in the summation are non-negative, for the sum to evaluate to one, $0 \le w(x \to y) \le \exp(-\beta[E(x) - E(y)])$. Thus, $w(x \to y) \to 0$ whenever $E(x) < E(y)$ as $\beta \to \infty$. If the Markov chain is not irreducible, one might end up in a local minima. This approach is known as \textbf{quench} in statistical physics.

To avoid the local minima issue, simulated annealing takes the approach of increasing $\beta$ over time so that the distribution $\mu_\beta$ slowly gets closer to the desired distribution $\mu_\beta(\sX_0^N)$. One decides on a sequence of values $\set{(\beta_i, n_i)}_{i=1}^L$, where $\set{\beta_i}_{i=1}^L$ forms an increasing sequence. A Markov chain is run with $\beta = \beta_i$ for $n_i$ steps before the value of $\beta$ is changed to $\beta_{i+1}$. Since $\beta$ gets bigger over time, the distribution $\mu_\beta$ gradually concentrates around states in $\sX_0^N$ while avoiding local minimas resulting due to non-irreversibility.

\section{Sanov's theorem}
Let $X \in \sX^N$ be a random vector with $N$ \emph{i.i.d.} $\sX$ valued random variables $X_1, \dots, X_N$ with the common underlying distribution $p \in \cM(\sX)$.  
We denote the type of a sequence by $\cT : \sX^N \to \cM(\sX)$ and write
\EQ{
\cT(X) = \frac{1}{N}\sum_{i=1}^N\indicator{X_i = x}. 
}
We can compute the probability of the type of a random sequence $X$ to be a distribution $q \in \cM(\sX)$ as 
\EQ{
P\set{\cT(X) = q} = \E\left[\prod_{x \in \sX}\indicator{Nq(x) =\sum_{i=1}^N\indicator{X_i = x}}\right].
}
We can write the above probability as an expectation of an integral
\EQ{
P\set{\cT(X) = q} = \E\left[\int\prod_{x \in \sX}\frac{d\lambda(x)}{2\pi}\exp\left(i\lambda(x)\left(Nq(x) - \sum_{i=1}^N\indicator{X_i = x}\right)\right)\right].
}
From the independence and identical distribution of $N$-length sequence $X$ and exchanging expectation and integral for the bounded integrand by bounded convergence theorem, we can write 
\EQ{
P\set{\cT(X) = q} =\int\prod_{x \in \sX}\frac{d\lambda(x)}{2\pi}\exp\left(i\lambda(x)Nq(x)\right) \left(\E\left[\exp\left(-i\sum_{x \in \sX}\lambda(x) \indicator{X_i = x}\right)\right]\right)^N.
}
Since the distribution of $X_i$ is $p(x)$, we have $\E\left[\exp\left(-i\sum_{x \in \sX}\lambda(x) \indicator{X_i = x}\right)\right] = \sum_{x \in \sX}p(x)e^{-i\lambda(x)}$.  
Therefore, we obtain $P\set{\cT(X) = q} =\int\prod_{x \in \sX}\frac{d\lambda(x)}{2\pi}e^{NS(\lambda)}$, 
where the exponent is called \textbf{action}
\EQ{
S(\lambda) = i \sum_{x \in \sX}\lambda(x)q(x) + \log\left(\sum_{x \in \sX}p(x)e^{-i\lambda(x)}\right).
}
For large particle limit $N \to \infty$, the probability of getting type $q$ from the sequence $X$ is dominated by the largest exponent $S(\lambda^\ast)$ where $\pd{S(\lambda)}{\lambda(x)} = 0$ for each $x \in \sX$. 
That is, 
\EQ{
iq(x) = \frac{ip(x)e^{-i\lambda^\ast(x)}}{\sum_{y \in \sX}p(y)e^{-i\lambda^\ast(y)}}
}
Let $C \triangleq \sum_{y \in \sX}p(y)e^{-i\lambda^\ast(y)}$, then we have $-i\lambda^\ast(x) = \log C + \log\frac{q(x)}{p(x)}$. 
Therefore, we obtain 
\EQ{
S(\lambda^\ast) = - \sum_xq(x)\log\frac{q(x)}{p(x)} = -D(q \Vert p). 
} 
\appendix
\section{Euler's identity}
%\section{Cauchy's integral theorem}
%Let $U$ be an open subset of the complex plane $\C$ such that $U$ contains the disk $D = \set{z \in \C: \abs{z-z_0} \le r}$. 
%Let $\gamma$ be the clockwise boundary circle of the disk $D$, then  for any holomorphic function $f: U \to \C$ and $a \in D^o$, we have
%\EQ{
%f(a) = \frac{1}{2\pi i}\oint \frac{f(z)}{z-a}dz.
%}
\begin{thm}
We can write the following equality in terms of integration with a scalar $\lambda(x)$ as 
\EQ{
\indicator{X_i = x} = \int_{0}^{2\pi}\frac{d\lambda(x)}{2\pi}\exp(i\lambda(x)(X_i- x)). 
}
Therefore, we can write the equality in terms of multi-dimensional integral in terms of vector $\lambda = (\lambda(x): x \in \sX)$ as 
\EQ{
\prod_{x \in \sX}\indicator{X_i = x} = \int\prod_{x \in \sX}\frac{d\lambda(x)}{2\pi}\exp(i\lambda(x)(X_i- x)). 
}
\end{thm}
\end{document}
